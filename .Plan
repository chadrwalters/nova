# Nova Development Plan

## Phase 1: Vector Store and File Ingestion [IN PROGRESS]

### Project Setup [COMPLETED]
- [x] Initialize uv environment
- [x] Create .nova directory structure
  - [x] Logs directory
  - [x] Processing directory
  - [x] Vector store directory
  - [x] System state directory
- [x] Configure input paths
- [x] Set up core dependencies in pyproject.toml
- [x] Create virtual environment with test/dev extras
- [x] Complete configuration system
  - [x] Create config/nova.yaml
  - [x] Implement config validation
  - [x] Add environment variable support
  - [x] API keys management
- [x] Set up local test runner

### Bear Export Processing [COMPLETED]
- [x] Create Bear ingestion module structure
- [x] Implement BearParser class
- [x] Add BearNote and BearAttachment data classes
- [x] Implement core parsing functionality
  - [x] Configure input directory handling
  - [x] Process markdown files
  - [x] Handle attachments
  - [x] Maintain link integrity
- [x] Create test suite
- [x] Run and validate tests
- [x] Add error recovery mechanisms
  - [x] BearParserError hierarchy
  - [x] Metadata validation
  - [x] Tag extraction validation
  - [x] Attachment error handling
- [x] Implement tag extraction
  - [x] Code block awareness
  - [x] Metadata validation
  - [x] Punctuation handling
  - [x] Nested tag support
- [x] Set up Docling integration
  - [x] Configure Python 3.10 environment
  - [x] Install Docling dependencies
  - [x] Implement OCR pipeline
  - [x] Add fallback mechanisms
    - [x] Multiple OCR configurations
    - [x] Confidence thresholds
    - [x] Error handling
  - [x] Create placeholder system
    - [x] Design placeholder format
    - [x] Implement placeholder generation
    - [x] Add placeholder tests
  - [x] Configure processing output to .nova directory
    - [x] Set up output directory structure
    - [x] Implement file management
    - [x] Add cleanup routines
- [x] Implement logging system
[MILESTONE: Run tests for export processing - PASSED]

### Vector Store Implementation [COMPLETED]
- [x] Design chunking engine
  - [x] Create ChunkingEngine class
  - [x] Implement heading-based segmentation
    - [x] Parse markdown headings
    - [x] Create hierarchical chunks
    - [x] Maintain heading context
  - [x] Add semantic content splitting
    - [x] Implement word boundary detection
    - [x] Add chunk size constraints
    - [x] Configure overlap settings
  - [x] Handle metadata preservation
    - [x] Track source locations
    - [x] Maintain tag associations
    - [x] Link to original notes
- [x] Create embedding pipeline
  - [x] Set up sentence transformer
  - [x] Implement batch processing
  - [x] Add caching layer
  - [x] Configure embedding options
- [x] Set up vector store
  - [x] FAISS/Chroma integration
  - [x] Implement dual storage
    - [x] Persistent store setup
    - [x] Ephemeral store handling
  - [x] Add index management
    - [x] Create indexing strategies
    - [x] Implement update mechanisms
    - [x] Add cleanup routines
- [x] Add vector store tests
  - [x] Unit tests for components
  - [x] Integration tests
  - [x] Performance benchmarks
[MILESTONE: Run tests for vector store - PASSED]

## Phase 2: RAG and MCP Integration [IN PROGRESS]

### CLI Consolidation [COMPLETED]
- [x] Create unified CLI entrypoint
  - [x] Create src/nova/cli directory structure
  - [x] Implement nova/cli/main.py dispatcher
  - [x] Add base command class with error handling
  - [x] Set up command registration system
- [x] Implement core commands
  - [x] process-notes: Bear note processing
    - [x] Move from process_notes.py
    - [x] Add command options
    - [x] Implement progress feedback
    - [x] Add error handling
  - [x] process-vectors: Vector operations
    - [x] Move from process_vectors.py
    - [x] Add command options
    - [x] Add batch processing flags
    - [x] Implement caching
  - [x] monitor: System monitoring
    - [x] Add health check command
    - [x] Add stats command
    - [x] Add logs command
- [x] Add console script entrypoints
  - [x] Update pyproject.toml
  - [x] Add nova command entrypoint
  - [x] Configure command discovery
- [x] Add CLI documentation
  - [x] Command reference
  - [x] Usage examples
  - [x] Error handling
- [x] Add tests for CLI
  - [x] Unit tests for commands
  - [x] Integration tests
  - [x] Command help tests
[MILESTONE: Run tests for CLI - PASSED]

### MCP Integration [NOT STARTED]
- [ ] Set up MCP Python SDK
  - [ ] Create dedicated mcp module (src/nova/mcp)
  - [ ] Implement interface for data retrieval
  - [ ] Add MCP adapter implementation
  - [ ] Configure API key handling
- [ ] Implement tool definitions
  - [ ] search_documentation tool
    - [ ] Vector store integration
    - [ ] Result formatting
    - [ ] Context assembly
  - [ ] list_sources tool
    - [ ] Source enumeration
    - [ ] Metadata collection
    - [ ] Status reporting
  - [ ] extract_content tool
    - [ ] Content retrieval
    - [ ] Format conversion
    - [ ] Metadata enrichment
  - [ ] remove_documentation tool
    - [ ] Safe deletion
    - [ ] Reference cleanup
    - [ ] Index updates
- [ ] Create context block handlers
  - [ ] Ephemeral block management
    - [ ] Memory-only storage
    - [ ] Lifecycle tracking
    - [ ] Cleanup routines
  - [ ] Resource block handling
    - [ ] Persistent storage
    - [ ] Version tracking
    - [ ] Access control
  - [ ] System instruction blocks
    - [ ] Template management
    - [ ] Dynamic updates
    - [ ] Context assembly
- [ ] Implement transport layer
  - [ ] Local IPC setup
    - [ ] Socket configuration
    - [ ] Protocol definition
    - [ ] Error handling
  - [ ] Async operations
    - [ ] Task scheduling
    - [ ] Resource limits
    - [ ] Timeout handling
  - [ ] Resource management
    - [ ] Connection pooling
    - [ ] Memory limits
    - [ ] Cleanup routines
- [ ] Add error handling
  - [ ] Failure recovery
    - [ ] Retry strategies
    - [ ] Fallback options
    - [ ] State recovery
  - [ ] Error messaging
    - [ ] User feedback
    - [ ] Log integration
    - [ ] Debug info
  - [ ] Retry logic
    - [ ] Backoff strategy
    - [ ] Failure thresholds
    - [ ] Circuit breaking
- [ ] Add tests for MCP integration
  - [ ] Unit tests for MCP adapter
    - [ ] Tool implementations
    - [ ] Block handlers
    - [ ] Transport layer
  - [ ] Integration tests with vector store
    - [ ] Search operations
    - [ ] Content extraction
    - [ ] Source management
  - [ ] Mock API tests
    - [ ] Request mocking
    - [ ] Response simulation
    - [ ] Error scenarios
[MILESTONE: Run tests for MCP integration]

### Monitoring Implementation [NOT STARTED]
- [ ] Create minimal web app
  - [ ] FastAPI-based server
  - [ ] Health check endpoint
  - [ ] Basic metrics display
- [ ] Add structured logging
  - [ ] Configure structlog
  - [ ] Define log format
  - [ ] Add log handlers
- [ ] Implement metrics collection
  - [ ] Vector store stats
  - [ ] Query performance
  - [ ] System health
- [ ] Create API endpoints
  - [ ] Health check
  - [ ] Recent ingestion stats
  - [ ] Vector store metrics
- [ ] Add tests for monitoring
  - [ ] Server tests
  - [ ] Metrics tests
  - [ ] Logging tests
[MILESTONE: Run tests for monitoring]

### Documentation Updates [NOT STARTED]
- [ ] Update README.md
  - [ ] Add uv setup instructions
  - [ ] Include quickstart guide
  - [ ] Document CLI usage
- [ ] Update architecture docs
  - [ ] Add MCP integration details
  - [ ] Document monitoring approach
  - [ ] Include performance considerations
- [ ] Create developer guide
  - [ ] Environment setup
  - [ ] Testing procedures
  - [ ] Contribution guidelines
[MILESTONE: Documentation review]

### RAG Implementation
- [ ] Create query processor
  - [ ] Tool-based decomposition
  - [ ] Context window management
  - [ ] Source attribution
- [ ] Implement retrieval system
  - [ ] Hybrid search functionality
  - [ ] Chunk selection logic
  - [ ] Dynamic context assembly
- [ ] Add result processor
  - [ ] Source validation
  - [ ] Metadata enrichment
  - [ ] Relevance scoring
- [ ] Create Claude interface
  - [ ] Anthropic API integration
  - [ ] Message formatting
  - [ ] Session management
- [ ] Add tests for RAG pipeline
[MILESTONE: Run tests for RAG system]

## Phase 3: Claude Desktop Integration [NOT STARTED]

### Desktop Client Setup
- [ ] Create desktop client structure
- [ ] Set up IPC mechanisms
  - [ ] Local communication
  - [ ] Resource management
- [ ] Implement Claude integration
  - [ ] MCP message handling
  - [ ] Response streaming
  - [ ] Error recovery
- [ ] Add tests for desktop client
[MILESTONE: Run tests for desktop integration]

### Desktop Features
- [ ] Create query interface
- [ ] Implement response display
- [ ] Add settings management
  - [ ] API key handling
  - [ ] Vector store config
- [ ] Implement error handling
- [ ] Add tests for desktop features
[MILESTONE: Run tests for desktop features]

## Phase 4: Monitoring System [NOT STARTED]

### Monitoring Backend
- [ ] Implement metrics collection
  - [ ] Vector store stats
  - [ ] Query performance
  - [ ] System health
- [ ] Create logging system
- [ ] Add performance tracking
- [ ] Create API endpoints
- [ ] Add tests for monitoring backend
[MILESTONE: Run tests for monitoring backend]

### Monitoring Frontend
- [ ] Create dashboard UI
- [ ] Implement metrics display
- [ ] Add log viewer
- [ ] Create system status page
- [ ] Add tests for monitoring frontend
[MILESTONE: Run tests for monitoring frontend]

# Current Focus
1. Begin MCP Integration
   - Set up MCP module structure
   - Design tool interfaces
   - Plan context block handling
2. Begin Monitoring Implementation
   - Design minimal web app structure
   - Plan metrics collection
   - Define API endpoints
3. Begin RAG Implementation
   - Design query processor
   - Plan retrieval system
   - Design result processor

# Blockers
1. MCP Integration
   - Official MCP SDK compatibility validation needed
   - Tool interface design decisions pending
   - Context block handling strategy to be finalized
2. Monitoring System
   - Web app framework selection pending
   - Metrics collection scope to be defined
   - API endpoint design needed
3. RAG Implementation
   - Query decomposition strategy needed
   - Context assembly approach pending
   - Source attribution design required
